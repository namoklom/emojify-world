{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bgPpghocFIa"
      },
      "source": [
        "# **Emojify World! (Text to Emoji with GloVe and LSTM)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bB9_XU8scbsD"
      },
      "source": [
        "## Table of Contents\n",
        "\n",
        "- [Packages](#0)\n",
        "- [1 - Baseline Model: Emojifier-V1](#1)\n",
        "    - [1.1 - Dataset EMOJISET](#1-1)\n",
        "    - [1.2 - Overview of the Emojifier-V1](#1-2)\n",
        "    - [1.3 - Implementing Emojifier-V1](#1-3)\n",
        "        - [1.3.1 - sentence_to_avg](#1-3-1)\n",
        "    - [1.4 - Implement the Model](#1-4)\n",
        "        - [1.4.1 - model](#1-4-1)\n",
        "    - [1.5 - Examining Test Set Performance](#1-5)\n",
        "- [2 - Emojifier-V2: Using LSTMs in Keras](#2)\n",
        "    - [2.1 - sentences_to_indices](#2-1)\n",
        "    - [2.2 - pretrained_embedding_layer](#2-2)\n",
        "    - [2.3 - Building the Emojifier-V2](#2-3)\n",
        "        - [2.3.1 - Emojify_V2](#2-3-1)\n",
        "    - [2.4 - Train the Model](#2-4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsztVBA8cFIg"
      },
      "source": [
        "<a name='0'></a>\n",
        "## Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "6FgrJFnZcbsF"
      },
      "outputs": [],
      "source": [
        "### v3.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lMZ9xg8MFHZU"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from emo_utils import *\n",
        "import emoji\n",
        "import matplotlib.pyplot as plt\n",
        "from test_utils import *\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Av0PwZYscFIh"
      },
      "source": [
        "<a name='1'></a>\n",
        "## 1 - Baseline Model: Emojifier-V1\n",
        "\n",
        "<a name='1-1'></a>\n",
        "### 1.1 - Dataset EMOJISET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OvuoZ8pWcFIi"
      },
      "outputs": [],
      "source": [
        "X_train, Y_train = read_csv('data/train_emoji.csv')\n",
        "X_test, Y_test = read_csv('data/tesss.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DjAuDbxrcFIi"
      },
      "outputs": [],
      "source": [
        "maxLen = len(max(X_train, key=lambda x: len(x.split())).split())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vE1Zd2SMcFIj",
        "outputId": "49f45ed1-8f2f-4ea8-da44-4acb41731287"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "never talk to me again üòû\n",
            "I am proud of your achievements üòÑ\n",
            "It is the worst day in my life üòû\n",
            "Miss you so much ‚ù§Ô∏è\n",
            "food is life üç¥\n",
            "I love you mum ‚ù§Ô∏è\n",
            "Stop saying bullshit üòû\n",
            "congratulations on your acceptance üòÑ\n",
            "The assignment is too long  üòû\n",
            "I want to go play ‚öæ\n"
          ]
        }
      ],
      "source": [
        "for idx in range(10):\n",
        "    print(X_train[idx], label_to_emoji(Y_train[idx]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tS_N2pMpcFIk"
      },
      "source": [
        "<a name='1-2'></a>\n",
        "### 1.2 - Overview of the Emojifier-V1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6nloeF5cFIl"
      },
      "source": [
        "#### One-hot Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RhRTRwVncFIm"
      },
      "outputs": [],
      "source": [
        "Y_oh_train = convert_to_one_hot(Y_train, C = 5)\n",
        "Y_oh_test = convert_to_one_hot(Y_test, C = 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GlHYeuBIcFIo",
        "outputId": "c2b73f6a-9a15-4728-a8b4-7ba38b5372ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sentence 'I missed you' has label index 0, which is emoji ‚ù§Ô∏è\n",
            "Label index 0 in one-hot encoding format is [1. 0. 0. 0. 0.]\n"
          ]
        }
      ],
      "source": [
        "idx = 50\n",
        "print(f\"Sentence '{X_train[idx]}' has label index {Y_train[idx]}, which is emoji {label_to_emoji(Y_train[idx])}\", )\n",
        "print(f\"Label index {Y_train[idx]} in one-hot encoding format is {Y_oh_train[idx]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KI8mJoafcFIp"
      },
      "source": [
        "<a name='1-3'></a>\n",
        "### 1.3 - Implementing Emojifier-V1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QXI3avt7cFIq"
      },
      "outputs": [],
      "source": [
        "word_to_index, index_to_word, word_to_vec_map = read_glove_vecs('data/glove.6B.50d.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RB2ZN6ajcFIr",
        "outputId": "3c733016-edf8-417d-f589-828c2a9d8a09"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "the index of cucumber in the vocabulary is 113317\n",
            "the 289846th word in the vocabulary is potatos\n"
          ]
        }
      ],
      "source": [
        "word = \"cucumber\"\n",
        "idx = 289846\n",
        "print(\"the index of\", word, \"in the vocabulary is\", word_to_index[word])\n",
        "print(\"the\", str(idx) + \"th word in the vocabulary is\", index_to_word[idx])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wg9QpkR5cFIs"
      },
      "source": [
        "<a name='ex-1'></a>\n",
        "### 1.3.1 - sentence_to_avg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "buYjsIBecFIs"
      },
      "outputs": [],
      "source": [
        "def sentence_to_avg(sentence, word_to_vec_map):\n",
        "    any_word = list(word_to_vec_map.keys())[0]\n",
        "    words = sentence.lower().split()\n",
        "    avg = np.zeros(word_to_vec_map[any_word].shape)\n",
        "    count = 0\n",
        "    for w in words:\n",
        "        if w in word_to_vec_map:\n",
        "            avg += word_to_vec_map[w]\n",
        "            count +=1\n",
        "    if count > 0:\n",
        "        avg = avg / count\n",
        "    return avg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "deletable": false,
        "editable": false,
        "id": "7OwW-r6ecFIt",
        "outputId": "7ed0ff55-10f4-4072-fdff-2edc216373fc",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "avg = \n",
            " [-0.008005    0.56370833 -0.50427333  0.258865    0.55131103  0.03104983\n",
            " -0.21013718  0.16893933 -0.09590267  0.141784   -0.15708967  0.18525867\n",
            "  0.6495785   0.38371117  0.21102167  0.11301667  0.02613967  0.26037767\n",
            "  0.05820667 -0.01578167 -0.12078833 -0.02471267  0.4128455   0.5152061\n",
            "  0.38756167 -0.898661   -0.535145    0.33501167  0.68806933 -0.2156265\n",
            "  1.797155    0.10476933 -0.36775333  0.750785    0.10282583  0.348925\n",
            " -0.27262833  0.66768    -0.10706167 -0.283635    0.59580117  0.28747333\n",
            " -0.3366635   0.23393817  0.34349183  0.178405    0.1166155  -0.076433\n",
            "  0.1445417   0.09808667]\n",
            "\u001b[92mAll tests passed!\n"
          ]
        }
      ],
      "source": [
        "### YOU CANNOT EDIT THIS CELL\n",
        "\n",
        "# BEGIN UNIT TEST\n",
        "avg = sentence_to_avg(\"Morrocan couscous is my favorite dish\", word_to_vec_map)\n",
        "print(\"avg = \\n\", avg)\n",
        "\n",
        "def sentence_to_avg_test(target):\n",
        "    # Create a controlled word to vec map\n",
        "    word_to_vec_map = {'a': [3, 3], 'synonym_of_a': [3, 3], 'a_nw': [2, 4], 'a_s': [3, 2],\n",
        "                       'c': [-2, 1], 'c_n': [-2, 2],'c_ne': [-1, 2], 'c_e': [-1, 1], 'c_se': [-1, 0],\n",
        "                       'c_s': [-2, 0], 'c_sw': [-3, 0], 'c_w': [-3, 1], 'c_nw': [-3, 2]\n",
        "                      }\n",
        "    # Convert lists to np.arrays\n",
        "    for key in word_to_vec_map.keys():\n",
        "        word_to_vec_map[key] = np.array(word_to_vec_map[key])\n",
        "\n",
        "    avg = target(\"a a_nw c_w a_s\", word_to_vec_map)\n",
        "    assert tuple(avg.shape) == tuple(word_to_vec_map['a'].shape),  \"Check the shape of your avg array\"\n",
        "    assert np.allclose(avg, [1.25, 2.5]),  \"Check that you are finding the 4 words\"\n",
        "    avg = target(\"love a a_nw c_w a_s\", word_to_vec_map)\n",
        "    assert np.allclose(avg, [1.25, 2.5]), \"Divide by count, not len(words)\"\n",
        "    avg = target(\"love\", word_to_vec_map)\n",
        "    assert np.array_equal(avg, [0, 0]), \"Average of no words must give an array of zeros\"\n",
        "    avg = target(\"c_se foo a a_nw c_w a_s deeplearning c_nw\", word_to_vec_map)\n",
        "    assert np.allclose(avg, [0.1666667, 2.0]), \"Debug the last example\"\n",
        "\n",
        "    print(\"\\033[92mAll tests passed!\")\n",
        "\n",
        "sentence_to_avg_test(sentence_to_avg)\n",
        "\n",
        "# END UNIT TEST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPPv5gmucFIv"
      },
      "source": [
        "<a name='1-4'></a>\n",
        "### 1.4 - Implement the Model\n",
        "\n",
        "<a name='ex-2'></a>\n",
        "### 1.4.1 - model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O_BzrO-TcFIv"
      },
      "outputs": [],
      "source": [
        "def model(X, Y, word_to_vec_map, learning_rate = 0.01, num_iterations = 400):\n",
        "    any_word = list(word_to_vec_map.keys())[0]\n",
        "    cost = 0\n",
        "\n",
        "    m = Y.shape[0]\n",
        "    n_y = len(np.unique(Y))\n",
        "    n_h = word_to_vec_map[any_word].shape[0]\n",
        "\n",
        "    W = np.random.randn(n_y, n_h) / np.sqrt(n_h)\n",
        "    b = np.zeros((n_y,))\n",
        "\n",
        "    Y_oh = convert_to_one_hot(Y, C = n_y)\n",
        "\n",
        "    for t in range(num_iterations):\n",
        "        for i in range(m):\n",
        "\n",
        "            avg = sentence_to_avg(X[i], word_to_vec_map)\n",
        "\n",
        "            z = np.dot(W, avg) + b\n",
        "            a = softmax(z)\n",
        "\n",
        "            cost = -np.sum(Y_oh[i] * np.log(a))\n",
        "\n",
        "            dz = a - Y_oh[i]\n",
        "            dW = np.dot(dz.reshape(n_y,1), avg.reshape(1, n_h))\n",
        "            db = dz\n",
        "\n",
        "            W = W - learning_rate * dW\n",
        "            b = b - learning_rate * db\n",
        "\n",
        "        if t % 100 == 0:\n",
        "            print(\"Epoch: \" + str(t) + \" --- cost = \" + str(cost))\n",
        "            pred = predict(X, Y, W, b, word_to_vec_map)\n",
        "\n",
        "    return pred, W, b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "5c_brPMOcbsU",
        "outputId": "0676077e-5cb1-4737-a04f-ade9e5022a13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0 --- cost = 0.05105772513207823\n",
            "Accuracy: 0.9166666666666666\n",
            "Epoch: 100 --- cost = 0.00970311068897676\n",
            "Accuracy: 1.0\n",
            "\u001b[92mAll tests passed!\n"
          ]
        }
      ],
      "source": [
        "### YOU CANNOT EDIT THIS CELL\n",
        "\n",
        "# UNIT TEST\n",
        "def model_test(target):\n",
        "    # Create a controlled word to vec map\n",
        "    word_to_vec_map = {'a': [3, 3], 'synonym_of_a': [3, 3], 'a_nw': [2, 4], 'a_s': [3, 2], 'a_n': [3, 4],\n",
        "                       'c': [-2, 1], 'c_n': [-2, 2],'c_ne': [-1, 2], 'c_e': [-1, 1], 'c_se': [-1, 0],\n",
        "                       'c_s': [-2, 0], 'c_sw': [-3, 0], 'c_w': [-3, 1], 'c_nw': [-3, 2]\n",
        "                      }\n",
        "    # Convert lists to np.arrays\n",
        "    for key in word_to_vec_map.keys():\n",
        "        word_to_vec_map[key] = np.array(word_to_vec_map[key])\n",
        "\n",
        "    # Training set. Sentences composed of a_* words will be of class 0 and sentences composed of c_* words will be of class 1\n",
        "    X = np.asarray(['a a_s synonym_of_a a_n c_sw', 'a a_s a_n c_sw', 'a_s  a a_n', 'synonym_of_a a a_s a_n c_sw', \" a_s a_n\",\n",
        "                    \" a a_s a_n c \", \" a_n  a c c c_e missing\",\n",
        "                   'c c_nw c_n c c_ne', 'c_e c c_se c_s', 'c_nw c a_s c_e c_e', 'c_e a_nw c_sw', 'c_sw c c_ne c_ne'])\n",
        "\n",
        "    Y = np.asarray([0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1])\n",
        "\n",
        "    np.random.seed(10)\n",
        "    pred, W, b = model(X, Y, word_to_vec_map, 0.0025, 110)\n",
        "\n",
        "    assert W.shape == (2, 2), \"W must be of shape 2 x 2\"\n",
        "    assert np.allclose(pred.transpose(), Y), \"Model must give a perfect accuracy\"\n",
        "    assert np.allclose(b[0], -1 * b[1]), \"b should be symmetric in this example\"\n",
        "\n",
        "    print(\"\\033[92mAll tests passed!\")\n",
        "\n",
        "model_test(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "umWTqRcpcFIw",
        "outputId": "7b74cb94-e98c-4936-98bc-693a3bb5f34e",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0 --- cost = 1.9520498812810076\n",
            "Accuracy: 0.3484848484848485\n",
            "Epoch: 100 --- cost = 0.07971818726014807\n",
            "Accuracy: 0.9318181818181818\n",
            "Epoch: 200 --- cost = 0.04456369243681402\n",
            "Accuracy: 0.9545454545454546\n",
            "Epoch: 300 --- cost = 0.03432267378786059\n",
            "Accuracy: 0.9696969696969697\n"
          ]
        }
      ],
      "source": [
        "np.random.seed(1)\n",
        "pred, W, b = model(X_train, Y_train, word_to_vec_map)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O862gcUicFIx"
      },
      "source": [
        "<a name='1-5'></a>\n",
        "### 1.5 - Examining Test Set Performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhb6CzhrcFIx",
        "outputId": "08d07fd0-55c2-4eff-d570-2562deb0570b",
        "scrolled": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training set:\n",
            "Accuracy: 0.9772727272727273\n",
            "Test set:\n",
            "Accuracy: 0.8571428571428571\n"
          ]
        }
      ],
      "source": [
        "print(\"Training set:\")\n",
        "pred_train = predict(X_train, Y_train, W, b, word_to_vec_map)\n",
        "print('Test set:')\n",
        "pred_test = predict(X_test, Y_test, W, b, word_to_vec_map)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwmrm-aDcFIy"
      },
      "source": [
        "#### The Model Matches Emojis to Relevant Words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvCl7fUvcFIz",
        "outputId": "a3913da3-85df-466d-dd8f-520245d495fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8333333333333334\n",
            "\n",
            "i treasure you ‚ù§Ô∏è\n",
            "i love you ‚ù§Ô∏è\n",
            "funny lol üòÑ\n",
            "lets play with a ball ‚öæ\n",
            "food is ready üç¥\n",
            "today is not good üòÑ\n"
          ]
        }
      ],
      "source": [
        "X_my_sentences = np.array([\"i treasure you\", \"i love you\", \"funny lol\", \"lets play with a ball\", \"food is ready\", \"today is not good\"])\n",
        "Y_my_labels = np.array([[0], [0], [2], [1], [4],[3]])\n",
        "\n",
        "pred = predict(X_my_sentences, Y_my_labels , W, b, word_to_vec_map)\n",
        "print_predictions(X_my_sentences, pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZyC-BGqKcFI0"
      },
      "source": [
        "#### Confusion Matrix\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "id": "Ab9aH9IQcFI1",
        "outputId": "d8cfc4cc-bbdc-487b-8efc-3d9a3cdbdd06"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(56,)\n",
            "           ‚ù§Ô∏è    ‚öæ    üòÑ    üòû   üç¥\n",
            "Predicted  0.0  1.0  2.0  3.0  4.0  All\n",
            "Actual                                 \n",
            "0            6    0    0    1    0    7\n",
            "1            0    8    0    0    0    8\n",
            "2            2    0   16    0    0   18\n",
            "3            1    1    2   12    0   16\n",
            "4            0    0    1    0    6    7\n",
            "All          9    9   19   13    6   56\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 288x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "print(Y_test.shape)\n",
        "print('           '+ label_to_emoji(0)+ '    ' + label_to_emoji(1) + '    ' +  label_to_emoji(2)+ '    ' + label_to_emoji(3)+'   ' + label_to_emoji(4))\n",
        "print(pd.crosstab(Y_test, pred_test.reshape(56,), rownames=['Actual'], colnames=['Predicted'], margins=True))\n",
        "plot_confusion_matrix(Y_test, pred_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BEeTqpjlcFI2"
      },
      "source": [
        "<a name='2'></a>\n",
        "## 2 - Emojifier-V2: Using LSTMs in Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPIihtFVFEbz"
      },
      "source": [
        "### Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uZ-fy9fYcFI3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow\n",
        "np.random.seed(0)\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Input, Dropout, LSTM, Activation\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.initializers import glorot_uniform\n",
        "np.random.seed(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KnoTtNWBcFI5"
      },
      "source": [
        "<a name='ex-3'></a>\n",
        "### 2.1 - sentences_to_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cMm64iWcFI5",
        "outputId": "f82cb8b2-991c-44ae-9c81-7a5235edeea2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 I\n",
            "1 like\n",
            "2 learning\n"
          ]
        }
      ],
      "source": [
        "for idx, val in enumerate([\"I\", \"like\", \"learning\"]):\n",
        "    print(idx, val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z0SixlIwcFI5"
      },
      "outputs": [],
      "source": [
        "def sentences_to_indices(X, word_to_index, max_len):\n",
        "    m = X.shape[0]\n",
        "\n",
        "    X_indices = np.zeros((m, max_len))\n",
        "\n",
        "    for i in range(m):\n",
        "        sentence_words = X[i].lower().split()\n",
        "        j = 0\n",
        "        for w in sentence_words:\n",
        "            if w in word_to_index:\n",
        "                X_indices[i, j] = word_to_index[w]\n",
        "                j =  j + 1\n",
        "    return X_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "DiW55_jHcbs2",
        "outputId": "64540426-9ab5-4355-cbfa-db79cd43ce77"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[1. 2. 4. 3.]\n",
            " [4. 8. 6. 5.]\n",
            " [5. 3. 7. 0.]\n",
            " [0. 0. 0. 0.]]\n",
            "\u001b[92mAll tests passed!\n"
          ]
        }
      ],
      "source": [
        "### YOU CANNOT EDIT THIS CELL\n",
        "\n",
        "# UNIT TEST\n",
        "def sentences_to_indices_test(target):\n",
        "\n",
        "    # Create a word_to_index dictionary\n",
        "    word_to_index = {}\n",
        "    for idx, val in enumerate([\"i\", \"like\", \"learning\", \"deep\", \"machine\", \"love\", \"smile\", '¬¥0.=']):\n",
        "        word_to_index[val] = idx + 1;\n",
        "\n",
        "    max_len = 4\n",
        "    sentences = np.array([\"I like deep learning\", \"deep ¬¥0.= love machine\", \"machine learning smile\", \"$\"]);\n",
        "    indexes = target(sentences, word_to_index, max_len)\n",
        "    print(indexes)\n",
        "\n",
        "    assert type(indexes) == np.ndarray, \"Wrong type. Use np arrays in the function\"\n",
        "    assert indexes.shape == (sentences.shape[0], max_len), \"Wrong shape of ouput matrix\"\n",
        "    assert np.allclose(indexes, [[1, 2, 4, 3],\n",
        "                                 [4, 8, 6, 5],\n",
        "                                 [5, 3, 7, 0],\n",
        "                                 [0, 0, 0, 0]]), \"Wrong values. Debug with the given examples\"\n",
        "\n",
        "    print(\"\\033[92mAll tests passed!\")\n",
        "\n",
        "sentences_to_indices_test(sentences_to_indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oBL1PMOCcFI6",
        "outputId": "6781359c-bafd-4ab5-a477-f8a5a86ea219"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X1 = ['funny lol' 'lets play baseball' 'food is ready for you']\n",
            "X1_indices =\n",
            " [[155345. 225122.      0.      0.      0.]\n",
            " [220930. 286375.  69714.      0.      0.]\n",
            " [151204. 192973. 302254. 151349. 394475.]]\n"
          ]
        }
      ],
      "source": [
        "X1 = np.array([\"funny lol\", \"lets play baseball\", \"food is ready for you\"])\n",
        "X1_indices = sentences_to_indices(X1, word_to_index, max_len=5)\n",
        "print(\"X1 =\", X1)\n",
        "print(\"X1_indices =\\n\", X1_indices)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0OJPAEM5cFI6"
      },
      "source": [
        "### 2.2 - pretrained_embedding_layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XBlEpiVkcFI7"
      },
      "outputs": [],
      "source": [
        "def pretrained_embedding_layer(word_to_vec_map, word_to_index):\n",
        "    vocab_size = len(word_to_index) + 1\n",
        "    any_word = list(word_to_vec_map.keys())[0]\n",
        "    emb_dim = word_to_vec_map[any_word].shape[0]\n",
        "    emb_matrix = np.zeros((vocab_size, emb_dim))\n",
        "    for word, idx in word_to_index.items():\n",
        "        emb_matrix[idx, :] = word_to_vec_map[word]\n",
        "    embedding_layer = Embedding(vocab_size, emb_dim, trainable=False)\n",
        "    embedding_layer.build((None,))\n",
        "    embedding_layer.set_weights([emb_matrix])\n",
        "    return embedding_layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "YfjCA3LTcbs6",
        "outputId": "9607f27a-6b2f-4bee-d4a9-a5e8f306f3df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[92mAll tests passed!\n"
          ]
        }
      ],
      "source": [
        "### YOU CANNOT EDIT THIS CELL\n",
        "\n",
        "# UNIT TEST\n",
        "def pretrained_embedding_layer_test(target):\n",
        "    # Create a controlled word to vec map\n",
        "    word_to_vec_map = {'a': [3, 3], 'synonym_of_a': [3, 3], 'a_nw': [2, 4], 'a_s': [3, 2], 'a_n': [3, 4],\n",
        "                       'c': [-2, 1], 'c_n': [-2, 2],'c_ne': [-1, 2], 'c_e': [-1, 1], 'c_se': [-1, 0],\n",
        "                       'c_s': [-2, 0], 'c_sw': [-3, 0], 'c_w': [-3, 1], 'c_nw': [-3, 2]\n",
        "                      }\n",
        "    # Convert lists to np.arrays\n",
        "    for key in word_to_vec_map.keys():\n",
        "        word_to_vec_map[key] = np.array(word_to_vec_map[key])\n",
        "\n",
        "    # Create a word_to_index dictionary\n",
        "    word_to_index = {}\n",
        "    for idx, val in enumerate(list(word_to_vec_map.keys())):\n",
        "        word_to_index[val] = idx;\n",
        "\n",
        "    np.random.seed(1)\n",
        "    embedding_layer = target(word_to_vec_map, word_to_index)\n",
        "\n",
        "    assert type(embedding_layer) == Embedding, \"Wrong type\"\n",
        "    assert embedding_layer.input_dim == len(list(word_to_vec_map.keys())) + 1, \"Wrong input shape\"\n",
        "    assert embedding_layer.output_dim == len(word_to_vec_map['a']), \"Wrong output shape\"\n",
        "    assert np.allclose(embedding_layer.get_weights(),\n",
        "                       [[[ 3, 3], [ 3, 3], [ 2, 4], [ 3, 2], [ 3, 4],\n",
        "                       [-2, 1], [-2, 2], [-1, 2], [-1, 1], [-1, 0],\n",
        "                       [-2, 0], [-3, 0], [-3, 1], [-3, 2], [ 0, 0]]]), \"Wrong vaulues\"\n",
        "    print(\"\\033[92mAll tests passed!\")\n",
        "\n",
        "\n",
        "pretrained_embedding_layer_test(pretrained_embedding_layer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gn4iGb0AcFI7",
        "outputId": "5bab44b5-bf23-4c6e-f891-429e8be34981"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "weights[0][1][1] = 0.39031\n",
            "Input_dim 400001\n",
            "Output_dim 50\n"
          ]
        }
      ],
      "source": [
        "embedding_layer = pretrained_embedding_layer(word_to_vec_map, word_to_index)\n",
        "print(\"weights[0][1][1] =\", embedding_layer.get_weights()[0][1][1])\n",
        "print(\"Input_dim\", embedding_layer.input_dim)\n",
        "print(\"Output_dim\",embedding_layer.output_dim)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uEsWnZ_2cFI7"
      },
      "source": [
        "<a name='2-4'></a>\n",
        "### 2.3 - Building the Emojifier-V2\n",
        "\n",
        "<a name='ex-5'></a>\n",
        "### 2.3.1 - Emojify_V2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pb2ugsSUcFI7"
      },
      "outputs": [],
      "source": [
        "def Emojify_V2(input_shape, word_to_vec_map, word_to_index):\n",
        "    sentence_indices = Input(input_shape, dtype='int32')\n",
        "    embedding_layer = pretrained_embedding_layer(word_to_vec_map, word_to_index)\n",
        "    embeddings = embedding_layer(sentence_indices)\n",
        "\n",
        "    X = LSTM(128, return_sequences=True)(embeddings)\n",
        "    X = Dropout(0.5)(X)\n",
        "    X = LSTM(128, return_sequences=False)(X)\n",
        "    X = Dropout(0.5)(X)\n",
        "    X = Dense(5)(X)\n",
        "    X = Activation('softmax')(X)\n",
        "\n",
        "    model = Model(sentence_indices, X)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "_sX7pkRhcbs9",
        "outputId": "31e826cc-abb6-43e1-b668-cc279622f3d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mAll tests passed!\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "### YOU CANNOT EDIT THIS CELL\n",
        "\n",
        "# UNIT TEST\n",
        "from tensorflow.python.keras.engine.functional import Functional\n",
        "\n",
        "def Emojify_V2_test(target):\n",
        "    # Create a controlled word to vec map\n",
        "    word_to_vec_map = {'a': [3, 3], 'synonym_of_a': [3, 3], 'a_nw': [2, 4], 'a_s': [3, 2], 'a_n': [3, 4],\n",
        "                       'c': [-2, 1], 'c_n': [-2, 2],'c_ne': [-1, 2], 'c_e': [-1, 1], 'c_se': [-1, 0],\n",
        "                       'c_s': [-2, 0], 'c_sw': [-3, 0], 'c_w': [-3, 1], 'c_nw': [-3, 2]\n",
        "                      }\n",
        "    # Convert lists to np.arrays\n",
        "    for key in word_to_vec_map.keys():\n",
        "        word_to_vec_map[key] = np.array(word_to_vec_map[key])\n",
        "\n",
        "    # Create a word_to_index dictionary\n",
        "    word_to_index = {}\n",
        "    for idx, val in enumerate(list(word_to_vec_map.keys())):\n",
        "        word_to_index[val] = idx;\n",
        "\n",
        "    maxLen = 4\n",
        "    model = target((maxLen,), word_to_vec_map, word_to_index)\n",
        "\n",
        "    assert type(model) == Functional, \"Make sure you have correctly created Model instance which converts \\\"sentence_indices\\\" into \\\"X\\\"\"\n",
        "\n",
        "    expectedModel = [['InputLayer', [(None, 4)], 0], ['Embedding', (None, 4, 2), 30], ['LSTM', (None, 4, 128), 67072, (None, 4, 2), 'tanh', True], ['Dropout', (None, 4, 128), 0, 0.5], ['LSTM', (None, 128), 131584, (None, 4, 128), 'tanh', False], ['Dropout', (None, 128), 0, 0.5], ['Dense', (None, 5), 645, 'linear'], ['Activation', (None, 5), 0]]\n",
        "    comparator(summary(model), expectedModel)\n",
        "\n",
        "\n",
        "Emojify_V2_test(Emojify_V2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8fLhXJ9ucFI8",
        "outputId": "02d98359-a43b-4780-bb17-3d36e060aa86",
        "scrolled": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"functional_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 10)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_3 (Embedding)      (None, 10, 50)            20000050  \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 10, 128)           91648     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 10, 128)           0         \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 128)               131584    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 5)                 645       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 5)                 0         \n",
            "=================================================================\n",
            "Total params: 20,223,927\n",
            "Trainable params: 223,877\n",
            "Non-trainable params: 20,000,050\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = Emojify_V2((maxLen,), word_to_vec_map, word_to_index)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mKIsZqqicFI8"
      },
      "source": [
        "#### Compile the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aMf79f45cFI9"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mX6NORy7cFI9"
      },
      "source": [
        "<a name='2-4'></a>\n",
        "### 2.4 - Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UgsBnWQqcFI-"
      },
      "outputs": [],
      "source": [
        "X_train_indices = sentences_to_indices(X_train, word_to_index, maxLen)\n",
        "Y_train_oh = convert_to_one_hot(Y_train, C = 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LtFpvyJicFI_",
        "scrolled": true,
        "outputId": "0bf5ddfe-59a1-45a3-b504-77b96a4846c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "5/5 [==============================] - 0s 25ms/step - loss: 1.5768 - accuracy: 0.2273\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 1.5038 - accuracy: 0.3182\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 1.4362 - accuracy: 0.3939\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 1.3486 - accuracy: 0.4848\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 1.2351 - accuracy: 0.5682\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 1.0849 - accuracy: 0.6667\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.9367 - accuracy: 0.6818\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.8411 - accuracy: 0.6818\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.7145 - accuracy: 0.7348\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.5922 - accuracy: 0.7879\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5864 - accuracy: 0.7803\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4895 - accuracy: 0.7955\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.5557 - accuracy: 0.7879\n",
            "Epoch 14/50\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4335 - accuracy: 0.8561\n",
            "Epoch 15/50\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.3870 - accuracy: 0.8788\n",
            "Epoch 16/50\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.3494 - accuracy: 0.8636\n",
            "Epoch 17/50\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.3084 - accuracy: 0.8939\n",
            "Epoch 18/50\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.3238 - accuracy: 0.8939\n",
            "Epoch 19/50\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.4006 - accuracy: 0.8712\n",
            "Epoch 20/50\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.3177 - accuracy: 0.8939\n",
            "Epoch 21/50\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.2205 - accuracy: 0.9015\n",
            "Epoch 22/50\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.2021 - accuracy: 0.9545\n",
            "Epoch 23/50\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.1604 - accuracy: 0.9697\n",
            "Epoch 24/50\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.1383 - accuracy: 0.9545\n",
            "Epoch 25/50\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.2144 - accuracy: 0.9242\n",
            "Epoch 26/50\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.1491 - accuracy: 0.9470\n",
            "Epoch 27/50\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.1183 - accuracy: 0.9697\n",
            "Epoch 28/50\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.1350 - accuracy: 0.9545\n",
            "Epoch 29/50\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.1493 - accuracy: 0.9545\n",
            "Epoch 30/50\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.5535 - accuracy: 0.8182\n",
            "Epoch 31/50\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.6536 - accuracy: 0.7803\n",
            "Epoch 32/50\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.4119 - accuracy: 0.8333\n",
            "Epoch 33/50\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.3030 - accuracy: 0.8864\n",
            "Epoch 34/50\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.2569 - accuracy: 0.9091\n",
            "Epoch 35/50\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.1855 - accuracy: 0.9394\n",
            "Epoch 36/50\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.1641 - accuracy: 0.9545\n",
            "Epoch 37/50\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.1264 - accuracy: 0.9697\n",
            "Epoch 38/50\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.1006 - accuracy: 0.9697\n",
            "Epoch 39/50\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0885 - accuracy: 0.9848\n",
            "Epoch 40/50\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0525 - accuracy: 1.0000\n",
            "Epoch 41/50\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0386 - accuracy: 0.9848\n",
            "Epoch 42/50\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0478 - accuracy: 0.9848\n",
            "Epoch 43/50\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0285 - accuracy: 1.0000\n",
            "Epoch 44/50\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0238 - accuracy: 0.9924\n",
            "Epoch 45/50\n",
            "5/5 [==============================] - 0s 32ms/step - loss: 0.0166 - accuracy: 1.0000\n",
            "Epoch 46/50\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0109 - accuracy: 1.0000\n",
            "Epoch 47/50\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0132 - accuracy: 1.0000\n",
            "Epoch 48/50\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0203 - accuracy: 0.9924\n",
            "Epoch 49/50\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0944 - accuracy: 0.9773\n",
            "Epoch 50/50\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0175 - accuracy: 0.9924\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x78c2705d44d0>"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(X_train_indices, Y_train_oh, epochs = 50, batch_size = 32, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sIbcdVibcFJA",
        "outputId": "65b06e6c-415e-4038-c6fd-3839b3fd39f1",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 0s 4ms/step - loss: 0.5131 - accuracy: 0.8750\n",
            "\n",
            "Test accuracy =  0.875\n"
          ]
        }
      ],
      "source": [
        "X_test_indices = sentences_to_indices(X_test, word_to_index, max_len = maxLen)\n",
        "Y_test_oh = convert_to_one_hot(Y_test, C = 5)\n",
        "loss, acc = model.evaluate(X_test_indices, Y_test_oh)\n",
        "print()\n",
        "print(\"Test accuracy = \", acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjMyEGmYcFJC",
        "outputId": "0e87d217-d501-40d1-a6c7-71d567643d52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Expected emoji:üòÑ prediction: he got a very nice raise\t‚ù§Ô∏è\n",
            "Expected emoji:üòÑ prediction: she got me a nice present\t‚ù§Ô∏è\n",
            "Expected emoji:üòÑ prediction: he is a good friend\t‚ù§Ô∏è\n",
            "Expected emoji:üòû prediction: This girl is messing with me\t‚ù§Ô∏è\n",
            "Expected emoji:‚ù§Ô∏è prediction: I love taking breaks\tüòû\n",
            "Expected emoji:üòÑ prediction: will you be my valentine\t‚ù§Ô∏è\n",
            "Expected emoji:üòû prediction: go away\t‚öæ\n"
          ]
        }
      ],
      "source": [
        "C = 5\n",
        "y_test_oh = np.eye(C)[Y_test.reshape(-1)]\n",
        "X_test_indices = sentences_to_indices(X_test, word_to_index, maxLen)\n",
        "pred = model.predict(X_test_indices)\n",
        "for i in range(len(X_test)):\n",
        "    x = X_test_indices\n",
        "    num = np.argmax(pred[i])\n",
        "    if(num != Y_test[i]):\n",
        "        print('Expected emoji:'+ label_to_emoji(Y_test[i]) + ' prediction: '+ X_test[i] + label_to_emoji(num).strip())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEgCsIE7cFJE",
        "outputId": "28d6942b-ad6b-461e-9904-191430145d85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "I cannot play ‚öæ\n"
          ]
        }
      ],
      "source": [
        "x_test = np.array(['I cannot play'])\n",
        "X_test_indices = sentences_to_indices(x_test, word_to_index, maxLen)\n",
        "print(x_test[0] +' '+  label_to_emoji(np.argmax(model.predict(X_test_indices))))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "zhyVzuThcFI4",
        "LUSzrFkYcFJF"
      ],
      "provenance": []
    },
    "coursera": {
      "schema_names": [
        "DLSC5W2-A2"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}